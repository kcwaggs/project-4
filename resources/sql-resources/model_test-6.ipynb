{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 13:23:47.223987: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>FG</th>\n",
       "      <th>G</th>\n",
       "      <th>GA</th>\n",
       "      <th>A</th>\n",
       "      <th>AB</th>\n",
       "      <th>B</th>\n",
       "      <th>mode_minor</th>\n",
       "      <th>mode_major</th>\n",
       "      <th>time_signature_4_4</th>\n",
       "      <th>time_signature_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>-18.967</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>122.046</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>-17.694</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>107.034</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>-27.670</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>130.137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>-9.007</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>104.955</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-19.275</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>140.256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  danceability  energy  loudness  speechiness  acousticness  \\\n",
       "0           2         0.700  0.1530   -18.967       0.0555         0.986   \n",
       "1           2         0.769  0.1370   -17.694       0.0478         0.989   \n",
       "2           5         0.375  0.0532   -27.670       0.0321         0.963   \n",
       "3          37         0.630  0.3740    -9.007       0.2270         0.861   \n",
       "4           3         0.556  0.1130   -19.275       0.0391         0.992   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  ...  FG  G  GA  A  AB  B  \\\n",
       "0          0.934000     0.111   0.5450  122.046  ...   0  0   0  0   0  0   \n",
       "1          0.957000     0.116   0.2590  107.034  ...   0  0   0  0   0  0   \n",
       "2          0.868000     0.110   0.0688  130.137  ...   0  0   0  0   0  0   \n",
       "3          0.000075     0.294   0.3730  104.955  ...   1  0   0  0   0  0   \n",
       "4          0.965000     0.111   0.2670  140.256  ...   0  0   0  0   0  0   \n",
       "\n",
       "   mode_minor  mode_major  time_signature_4_4  time_signature_other  \n",
       "0           0           1                   0                     1  \n",
       "1           0           1                   1                     0  \n",
       "2           0           1                   1                     0  \n",
       "3           0           1                   1                     0  \n",
       "4           0           1                   0                     1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "def load_notebook(path):\n",
    "    # Load the notebook\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Convert the notebook to a Python script\n",
    "    exporter = PythonExporter()\n",
    "    source, _ = exporter.from_notebook_node(nb)\n",
    "    \n",
    "    # Create an interactive shell to execute the script\n",
    "    shell = InteractiveShell.instance()\n",
    "    \n",
    "    # Suppress standard output and error\n",
    "    old_stdout = sys.stdout\n",
    "    old_stderr = sys.stderr\n",
    "    sys.stdout = StringIO()\n",
    "    sys.stderr = StringIO()\n",
    "    \n",
    "    try:\n",
    "        # Execute the Python script\n",
    "        exec(source, shell.user_ns)\n",
    "    finally:\n",
    "        # Restore standard output and error\n",
    "        sys.stdout = old_stdout\n",
    "        sys.stderr = old_stderr\n",
    "    \n",
    "    return shell.user_ns\n",
    "\n",
    "# Specify the path to your notebook\n",
    "notebook_path = 'sql.ipynb'\n",
    "\n",
    "# Load the notebook and extract the namespace\n",
    "notebook_ns = load_notebook(notebook_path)\n",
    "\n",
    "# Access each of the dataframes\n",
    "model_one_df = notebook_ns['model_one_df']\n",
    "model_two_df = notebook_ns['model_two_df']\n",
    "model_three_df = notebook_ns['model_three_df']\n",
    "model_four_df = notebook_ns['model_four_df']\n",
    "model_five_df = notebook_ns['model_five_df']\n",
    "model_six_df = notebook_ns['model_six_df']\n",
    "model_seven_df = notebook_ns['model_seven_df']\n",
    "model_eight_df = notebook_ns['model_eight_df']\n",
    "\n",
    "# Print the head of each dataframe\n",
    "model_six_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = model_six_df.drop(columns=['popularity'])\n",
    "y = model_six_df['popularity']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                2160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4621 (18.05 KB)\n",
      "Trainable params: 4621 (18.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer\n",
    "nn = tf.keras.models.Sequential()\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4963/4963 [==============================] - 7s 1ms/step - loss: -28818212864.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -37628653568.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -48069636096.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -60269961216.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -74388283392.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -90536419328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -108882632704.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -129518510080.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -152627658752.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "4963/4963 [==============================] - 8s 2ms/step - loss: -178290491392.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "4963/4963 [==============================] - 9s 2ms/step - loss: -206640463872.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "4963/4963 [==============================] - 11s 2ms/step - loss: -237864796160.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "4963/4963 [==============================] - 10s 2ms/step - loss: -272099868672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "4963/4963 [==============================] - 10s 2ms/step - loss: -309430747136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "4963/4963 [==============================] - 6s 1ms/step - loss: -350014275584.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "4963/4963 [==============================] - 6s 1ms/step - loss: -394014556160.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "4963/4963 [==============================] - 5s 1ms/step - loss: -441741508608.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "4963/4963 [==============================] - 5s 1ms/step - loss: -493028048896.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "4963/4963 [==============================] - 5s 1ms/step - loss: -548261789696.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "4963/4963 [==============================] - 5s 1ms/step - loss: -607523831808.0000 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1655/1655 - 2s - loss: -6.3785e+11 - accuracy: 0.0000e+00 - 2s/epoch - 1ms/step\n",
      "Loss: -637850550272.0, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CaseyWaggoner/miniconda3/envs/dev/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save('Models/PopularityModel-6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
